{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6s23QSpgEVf"
      },
      "source": [
        "# RL Basics (Agent–Environment–Reward Loop)\n",
        "Identify Agent, Environment, State, Action, Reward.\n",
        "\n",
        "Learn the core RL loop using a toy Python example."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Agent**: Decision maker\n",
        "- **Environment**: World the agent interacts with\n",
        "- **State (s)**: Situation of the environment\n",
        "- **Action (a)**: Choice agent makes\n",
        "- **Reward (r)**: Feedback\n",
        "- **Policy (π)**: Mapping from state to action\n"
      ],
      "metadata": {
        "id": "AGMAkyCbkwOH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Q6oBnmgEVv",
        "outputId": "18594d90-3b80-42fc-8130-d358406a7c1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: State=User Waiting, Action=Ask Selection, Reward=1\n",
            "Step 1: State=Idle, Action=Ask Selection, Reward=0\n",
            "Step 2: State=Idle, Action=Dispense Soda, Reward=-2\n",
            "Step 3: State=User Waiting, Action=Dispense Water, Reward=3\n",
            "Step 4: State=User Waiting, Action=Ask Selection, Reward=1\n"
          ]
        }
      ],
      "source": [
        "# Toy RL loop example\n",
        "import random\n",
        "states = ['Idle','User Waiting']\n",
        "actions = ['Dispense Water','Dispense Soda','Ask Selection']\n",
        "reward_map = {\n",
        "    ('User Waiting','Ask Selection'): 1,\n",
        "    ('User Waiting','Dispense Soda'): 5,\n",
        "    ('User Waiting','Dispense Water'): 3,\n",
        "    ('Idle','Ask Selection'): 0,\n",
        "    ('Idle','Dispense Soda'): -2,\n",
        "    ('Idle','Dispense Water'): -2,\n",
        "}\n",
        "state = 'User Waiting'\n",
        "for step in range(5):\n",
        "    action = random.choice(actions)\n",
        "    reward = reward_map.get((state, action), 0)\n",
        "    print(f\"Step {step}: State={state}, Action={action}, Reward={reward}\")\n",
        "    state = random.choice(states)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMalYVeRgEV3"
      },
      "source": [
        "## Map RL Elements to Real-World Scenarios"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Scenario 1: Traffic Light System\n",
        "- **Agent**: Traffic signal controller\n",
        "- **Environment**: Road with cars and pedestrians\n",
        "- **State**: Traffic density (low/medium/high)\n",
        "- **Action**: Change signal (red/green/yellow)\n",
        "- **Reward**: Smooth traffic flow (positive), congestion (negative)"
      ],
      "metadata": {
        "id": "ItwCeFAtgYLf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63a96e5d",
        "outputId": "d3ff0bed-4281-4afa-8bca-2bbbf3a016a1"
      },
      "source": [
        "import random\n",
        "\n",
        "# Define the elements of the RL problem\n",
        "states = ['Low Traffic', 'Medium Traffic', 'High Traffic']\n",
        "actions = ['Change to Red', 'Change to Green', 'Change to Yellow']\n",
        "reward_map = {\n",
        "    ('Low Traffic', 'Change to Green'): 2,\n",
        "    ('Low Traffic', 'Change to Yellow'): 0,\n",
        "    ('Low Traffic', 'Change to Red'): -1,\n",
        "    ('Medium Traffic', 'Change to Green'): 1,\n",
        "    ('Medium Traffic', 'Change to Yellow'): 0,\n",
        "    ('Medium Traffic', 'Change to Red'): -1,\n",
        "    ('High Traffic', 'Change to Green'): -2,\n",
        "    ('High Traffic', 'Change to Yellow'): -1,\n",
        "    ('High Traffic', 'Change to Red'): 2,\n",
        "}\n",
        "\n",
        "# Simulate the RL loop\n",
        "state = random.choice(states)\n",
        "print(f\"Initial State: {state}\")\n",
        "\n",
        "for step in range(10):\n",
        "    action = random.choice(actions)\n",
        "    reward = reward_map.get((state, action), -3) # Default negative reward for invalid actions\n",
        "    print(f\"Step {step}: State={state}, Action={action}, Reward={reward}\")\n",
        "\n",
        "    # Simulate a transition to a new state (simplified)\n",
        "    state = random.choice(states)\n",
        "\n",
        "print(\"Simulation finished.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial State: High Traffic\n",
            "Step 0: State=High Traffic, Action=Change to Yellow, Reward=-1\n",
            "Step 1: State=Medium Traffic, Action=Change to Yellow, Reward=0\n",
            "Step 2: State=High Traffic, Action=Change to Red, Reward=2\n",
            "Step 3: State=Medium Traffic, Action=Change to Green, Reward=1\n",
            "Step 4: State=Low Traffic, Action=Change to Green, Reward=2\n",
            "Step 5: State=Medium Traffic, Action=Change to Yellow, Reward=0\n",
            "Step 6: State=Low Traffic, Action=Change to Green, Reward=2\n",
            "Step 7: State=High Traffic, Action=Change to Yellow, Reward=-1\n",
            "Step 8: State=Medium Traffic, Action=Change to Green, Reward=1\n",
            "Step 9: State=Medium Traffic, Action=Change to Red, Reward=-1\n",
            "Simulation finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 2: Dog Training\n",
        "- **Agent**: Dog\n",
        "- **Environment**: Training ground with trainer\n",
        "- **State**: Command given (sit, run)\n",
        "- **Action**: Dog's response (sit/run/ignore)\n",
        "- **Reward**: Biscuit (positive), no treat (0)"
      ],
      "metadata": {
        "id": "lbaHmynVkU6H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "827f827d",
        "outputId": "c30836a5-cc18-4bce-bcb2-76df1aed1d94"
      },
      "source": [
        "import random\n",
        "\n",
        "# Define the elements of the RL problem for Dog Training\n",
        "states = ['Sit Command', 'Run Command']\n",
        "actions = ['Sit', 'Run', 'Ignore']\n",
        "reward_map = {\n",
        "    ('Sit Command', 'Sit'): 1,\n",
        "    ('Sit Command', 'Run'): -1,\n",
        "    ('Sit Command', 'Ignore'): 0,\n",
        "    ('Run Command', 'Run'): 1,\n",
        "    ('Run Command', 'Sit'): -1,\n",
        "    ('Run Command', 'Ignore'): 0,\n",
        "}\n",
        "\n",
        "# Simulate the RL loop for Dog Training\n",
        "state = random.choice(states)\n",
        "print(f\"Initial State: {state}\")\n",
        "\n",
        "for step in range(5):\n",
        "    action = random.choice(actions)\n",
        "    reward = reward_map.get((state, action), -0.5) # Default slight negative reward for unexpected actions\n",
        "    print(f\"Step {step}: State={state}, Action={action}, Reward={reward}\")\n",
        "\n",
        "    # Simulate a transition to a new state (simplified)\n",
        "    state = random.choice(states)\n",
        "\n",
        "print(\"Simulation finished.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial State: Run Command\n",
            "Step 0: State=Run Command, Action=Run, Reward=1\n",
            "Step 1: State=Sit Command, Action=Sit, Reward=1\n",
            "Step 2: State=Sit Command, Action=Run, Reward=-1\n",
            "Step 3: State=Sit Command, Action=Ignore, Reward=0\n",
            "Step 4: State=Sit Command, Action=Sit, Reward=1\n",
            "Simulation finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 3: Warehouse Picking Robot\n",
        "- **Agent**: Robot\n",
        "- **Environment**: Warehouse grid\n",
        "- **State**: Current robot location + item request\n",
        "- **Action**: Move left/right/up/down or pick item\n",
        "- **Reward**: Correct pick (positive), wrong pick (negative), delay (negative)\n"
      ],
      "metadata": {
        "id": "TJ6ynd7wgbt7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6036a98",
        "outputId": "e0a2bc72-f1f7-44a8-f1a0-f053cd626ec7"
      },
      "source": [
        "import random\n",
        "\n",
        "# Define the elements of the RL problem for Warehouse Picking Robot\n",
        "# States can be simplified to just the task\n",
        "states = ['Picking Item']\n",
        "# Actions include movement and the final pick\n",
        "actions = ['Move Left', 'Move Right', 'Move Up', 'Move Down', 'Pick Item']\n",
        "reward_map = {\n",
        "    ('Picking Item', 'Pick Item'): 10,  # High reward for successful pick\n",
        "    ('Picking Item', 'Move Left'): -0.1, # Small negative reward for movement (cost)\n",
        "    ('Picking Item', 'Move Right'): -0.1,\n",
        "    ('Picking Item', 'Move Up'): -0.1,\n",
        "    ('Picking Item', 'Move Down'): -0.1,\n",
        "}\n",
        "\n",
        "# Simulate the RL loop for Warehouse Picking Robot (simplified)\n",
        "state = 'Picking Item'\n",
        "print(f\"Initial State: {state}\")\n",
        "\n",
        "for step in range(7): # Simulate a few steps of movement and potentially a pick\n",
        "    action = random.choice(actions)\n",
        "    # Reward for picking is only given if the state is 'Picking Item' and the action is 'Pick Item'\n",
        "    # Otherwise, movement has a small negative reward\n",
        "    if state == 'Picking Item' and action == 'Pick Item':\n",
        "        reward = reward_map.get((state, action), 0)\n",
        "        # In a real scenario, a successful pick would likely end the episode or transition to a new state\n",
        "        # For this simulation, we'll just give the reward and continue\n",
        "        print(f\"Step {step}: State={state}, Action={action}, Reward={reward} - Item Picked!\")\n",
        "    else:\n",
        "         reward = reward_map.get((state, action), -1) # Larger negative reward for picking at the wrong time or other invalid actions\n",
        "         print(f\"Step {step}: State={state}, Action={action}, Reward={reward}\")\n",
        "\n",
        "\n",
        "print(\"Simulation finished.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial State: Picking Item\n",
            "Step 0: State=Picking Item, Action=Move Right, Reward=-0.1\n",
            "Step 1: State=Picking Item, Action=Move Down, Reward=-0.1\n",
            "Step 2: State=Picking Item, Action=Move Left, Reward=-0.1\n",
            "Step 3: State=Picking Item, Action=Move Up, Reward=-0.1\n",
            "Step 4: State=Picking Item, Action=Move Right, Reward=-0.1\n",
            "Step 5: State=Picking Item, Action=Move Right, Reward=-0.1\n",
            "Step 6: State=Picking Item, Action=Pick Item, Reward=10 - Item Picked!\n",
            "Simulation finished.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}